'use client';

import { useEffect, useRef, useState } from 'react';
import * as faceapi from 'face-api.js';

interface MainProps {
  setIsAuthenticated: (authenticated: boolean) => void;
}

// âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ (ë²¡í„° ë¹„êµ)
const cosineSimilarity = (vecA: Float32Array, vecB: Float32Array) => {
  const dotProduct = vecA.reduce((sum, a, i) => sum + a * vecB[i], 0);
  const normA = Math.sqrt(vecA.reduce((sum, a) => sum + a * a, 0));
  const normB = Math.sqrt(vecB.reduce((sum, b) => sum + b * b, 0));
  return dotProduct / (normA * normB);
};

export default function Main({ setIsAuthenticated }: MainProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [isDetecting, setIsDetecting] = useState(false);

  useEffect(() => {
    const loadModels = async () => {
      try {
        console.log('ğŸ“¥ ëª¨ë¸ ë¡œë“œ ì‹œì‘...');
        await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
        await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        console.log('âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ');
      } catch (error) {
        console.error('âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
      }
    };
    loadModels();
  }, []);

  const handleFaceCheck = async () => {
    console.log('ğŸ”µ handleFaceCheck() ì‹¤í–‰ë¨');

    if (!videoRef.current) {
      console.log('âŒ videoRef ì—†ìŒ');
      return;
    }
    if (isDetecting) {
      console.log('âŒ ì´ë¯¸ ê°ì§€ ì¤‘');
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      videoRef.current.srcObject = stream;
      console.log('âœ… ì›¹ìº  ì‹¤í–‰ ì„±ê³µ');

      setTimeout(() => startFaceDetection(), 1000);
    } catch (err) {
      console.error('âŒ ì›¹ìº  ì ‘ê·¼ ì˜¤ë¥˜:', err);
    }
  };

  const startFaceDetection = () => {
    console.log('ğŸš€ ì–¼êµ´ ê°ì§€ ì‹œì‘ (5ì´ˆ ë™ì•ˆ ë°ì´í„° ìˆ˜ì§‘)!');
    if (!videoRef.current || !canvasRef.current) return;

    setIsDetecting(true);

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // âœ… ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì •
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    faceapi.matchDimensions(canvas, { width: video.videoWidth, height: video.videoHeight });

    const options = new faceapi.SsdMobilenetv1Options({
      minConfidence: 0.1,
      maxResults: 1,
    });

    let collectedDescriptors: Float32Array[] = [];
    const detectionInterval = 200;
    const totalTime = 5000;
    let elapsedTime = 0;

    const intervalId = setInterval(async () => {
      const detections = await faceapi.detectSingleFace(video, options).withFaceLandmarks().withFaceDescriptor();

      ctx.clearRect(0, 0, canvas.width, canvas.height);

      if (detections) {
        console.log(`ğŸ§ ì–¼êµ´ ê°ì§€ë¨ (${elapsedTime / 1000}s):`, detections);
        collectedDescriptors.push(detections.descriptor);
        drawFaceBox(ctx, detections);
      } else {
        console.log('âŒ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ - ì¡°ëª… ë˜ëŠ” ê±°ë¦¬ í™•ì¸');
      }

      elapsedTime += detectionInterval;
      if (elapsedTime >= totalTime) {
        clearInterval(intervalId);
        finalizeFaceDetection(collectedDescriptors);
      }
    }, detectionInterval);
  };

  const finalizeFaceDetection = (collectedDescriptors: Float32Array[]) => {
    console.log('ğŸ“Š ì–¼êµ´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ:', collectedDescriptors.length, 'ê°œì˜ ë°ì´í„°');

    if (collectedDescriptors.length === 0) {
      console.log('âŒ ì–¼êµ´ ê°ì§€ ë°ì´í„° ì—†ìŒ, ì¸ì¦ ì‹¤íŒ¨');
      alert('âŒ ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      setIsDetecting(false);
      return;
    }

    // âœ… ì–¼êµ´ ë°ì´í„° í‰ê· í™”
    const vectorLength = collectedDescriptors[0].length;
    const averagedDescriptor = new Float32Array(vectorLength).fill(0);

    collectedDescriptors.forEach((descriptor) => {
      for (let i = 0; i < vectorLength; i++) {
        averagedDescriptor[i] += descriptor[i];
      }
    });

    for (let i = 0; i < vectorLength; i++) {
      averagedDescriptor[i] /= collectedDescriptors.length;
    }

    console.log('âœ… ì–¼êµ´ ë°ì´í„° í‰ê· í™” ì™„ë£Œ:', averagedDescriptor);
    authenticateWithStoredData(averagedDescriptor);
  };

  const authenticateWithStoredData = (averagedDescriptor: Float32Array) => {
    const storedFaceData = localStorage.getItem('faceData');
    if (!storedFaceData) {
      console.log('âŒ ë“±ë¡ëœ ì–¼êµ´ ë°ì´í„° ì—†ìŒ');
      alert('âŒ ë“±ë¡ëœ ì–¼êµ´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
      setIsDetecting(false);
      return;
    }

    const storedDescriptors: { descriptor: number[] }[] = JSON.parse(storedFaceData);
    let maxSimilarity = -1;
    const similarityList: { index: number; similarity: number }[] = [];

    console.log(`ğŸ§ ì¸ì¦ ì‹œì‘! ì €ì¥ëœ ì–¼êµ´ ë°ì´í„° ê°œìˆ˜: ${storedDescriptors.length}`);

    storedDescriptors.forEach((data, index) => {
      const storedDescriptor = new Float32Array(data.descriptor);
      const similarity = cosineSimilarity(averagedDescriptor, storedDescriptor);
      similarityList.push({ index, similarity });

      if (similarity > maxSimilarity) {
        maxSimilarity = similarity;
      }
    });

    similarityList.sort((a, b) => b.similarity - a.similarity);
    console.log('ğŸ“Š ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼:', similarityList);
    console.log('ğŸ“ ìµœì¢… ìµœëŒ€ ìœ ì‚¬ë„:', maxSimilarity);

    if (maxSimilarity >= 0.99999) {
      setIsAuthenticated(true);
      console.log('âœ… ì–¼êµ´ ì¸ì¦ ì„±ê³µ!');
      alert(`âœ… ì–¼êµ´ ì¸ì¦ ì„±ê³µ! (ìµœëŒ€ ìœ ì‚¬ë„: ${(maxSimilarity * 100).toFixed(2)}%)`);
    } else {
      console.log('âŒ ì–¼êµ´ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      alert(`âŒ ì–¼êµ´ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ìµœëŒ€ ìœ ì‚¬ë„: ${(maxSimilarity * 100).toFixed(2)}%)`);
    }

    setIsDetecting(false);
  };

  const drawFaceBox = (
    ctx: CanvasRenderingContext2D,
    detections: faceapi.WithFaceLandmarks<{ detection: faceapi.FaceDetection }>
  ) => {
    const { x, y, width, height } = detections.detection.box;
    ctx.strokeStyle = 'red';
    ctx.lineWidth = 3;
    ctx.strokeRect(x, y, width, height);
    ctx.fillStyle = 'red';
    ctx.font = '14px Arial';
    ctx.fillText(`X: ${Math.round(x)}, Y: ${Math.round(y)}`, x, y - 10);
  };

  return (
    <div className="relative flex flex-col items-center">
      <video ref={videoRef} autoPlay muted className="border rounded w-80 h-60" />
      <canvas ref={canvasRef} className="absolute top-0 w-80 h-60" />
      <button onClick={handleFaceCheck} className="mt-2 p-2 bg-green-500 text-white rounded">
        ì–¼êµ´ ì¸ì¦í•˜ê¸°
      </button>
    </div>
  );
}
