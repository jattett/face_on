'use client';

import { useEffect, useRef, useState } from 'react';
import * as faceapi from 'face-api.js';

// ì–¼êµ´ ë°ì´í„° ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ì €ì¥ (ìµœëŒ€ 30ê°œ ìœ ì§€)
const saveFaceDataToLocalStorage = (descriptor: Float32Array) => {
  const storedData = localStorage.getItem('faceData');
  const faceList = storedData ? JSON.parse(storedData) : [];

  if (faceList.length >= 30) {
    faceList.shift(); // ê°€ì¥ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ
    console.log('ğŸ—‘ï¸ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ');
  }

  faceList.push({ descriptor: Array.from(descriptor), timestamp: Date.now() });
  localStorage.setItem('faceData', JSON.stringify(faceList));

  console.log('âœ… ì–¼êµ´ ë°ì´í„° ì €ì¥ ì™„ë£Œ:', faceList);
};

export default function FaceRecognition() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [capturedData, setCapturedData] = useState<Float32Array | null>(null);
  const [isDetecting, setIsDetecting] = useState(false);

  useEffect(() => {
    const loadModels = async () => {
      try {
        console.log('ğŸ“¥ ëª¨ë¸ ë¡œë“œ ì‹œì‘...');
        await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
        await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        console.log('âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ');
      } catch (error) {
        console.error('âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
      }
    };
    loadModels();
  }, []);

  const handleFaceRegister = async () => {
    if (!videoRef.current || !canvasRef.current) return;

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 1280, height: 720 }, // ğŸ“Œ í•´ìƒë„ë¥¼ ë†’ì—¬ ì–¼êµ´ ê°ì§€ ì„±ëŠ¥ í–¥ìƒ
      });

      videoRef.current.srcObject = stream;
      console.log('âœ… ì›¹ìº  ì‹¤í–‰ ì„±ê³µ');

      videoRef.current.onloadedmetadata = () => {
        console.log(`ğŸ¥ ë¹„ë””ì˜¤ í•´ìƒë„: ${videoRef.current?.videoWidth} x ${videoRef.current?.videoHeight}`);
        detectFace();
      };
    } catch (err) {
      console.error('âŒ ì›¹ìº  ì ‘ê·¼ ì˜¤ë¥˜:', err);
    }
  };

  const detectFace = async () => {
    if (!videoRef.current || !canvasRef.current || isDetecting) return;
    setIsDetecting(true);

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    faceapi.matchDimensions(canvas, { width: video.videoWidth, height: video.videoHeight });

    console.log('ğŸš€ ì–¼êµ´ ê°ì§€ ì‹œì‘...');
    const options = new faceapi.SsdMobilenetv1Options({
      minConfidence: 0.05,
      maxResults: 1,
    });

    const detectionResults: Float32Array[] = [];
    const detectionInterval = 200; // 200msë§ˆë‹¤ ê°ì§€
    const totalTime = 5000; // 5ì´ˆ ë™ì•ˆ ê°ì§€
    let elapsedTime = 0;

    const intervalId = setInterval(async () => {
      const detections = await faceapi.detectSingleFace(video, options).withFaceLandmarks().withFaceDescriptor();

      if (detections) {
        console.log(`ğŸ§ ì–¼êµ´ ê°ì§€ë¨: ${elapsedTime / 1000}s`, detections);
        detectionResults.push(detections.descriptor);
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        drawDetailedFaceInfo(ctx, detections);
      } else {
        console.log('âŒ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ - ì¡°ëª…ì„ ë°ê²Œ í•˜ê³ , ì–¼êµ´ì„ ì¹´ë©”ë¼ ì¤‘ì•™ì— ìœ„ì¹˜ì‹œí‚¤ì„¸ìš”.');
      }

      elapsedTime += detectionInterval;
      if (elapsedTime >= totalTime) {
        clearInterval(intervalId); // 5ì´ˆ í›„ ê°ì§€ ì¢…ë£Œ
        processAndSaveFaceData(detectionResults);
        stopCamera();
        setIsDetecting(false);
      }
    }, detectionInterval);
  };

  const processAndSaveFaceData = (detectionResults: Float32Array[]) => {
    if (detectionResults.length === 0) {
      console.log('âŒ ì–¼êµ´ ê°ì§€ ë°ì´í„° ì—†ìŒ, ì €ì¥í•˜ì§€ ì•ŠìŒ');
      return;
    }

    // âœ… ì—¬ëŸ¬ ê°œì˜ ê°ì§€ ë°ì´í„°ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥ (ë” ì •í™•í•œ ë°ì´í„° í™•ë³´)
    const numVectors = detectionResults.length;
    const vectorLength = detectionResults[0].length;
    const averagedDescriptor = new Float32Array(vectorLength).fill(0);

    detectionResults.forEach((descriptor) => {
      for (let i = 0; i < vectorLength; i++) {
        averagedDescriptor[i] += descriptor[i];
      }
    });

    for (let i = 0; i < vectorLength; i++) {
      averagedDescriptor[i] /= numVectors;
    }

    console.log('âœ… ì–¼êµ´ ë°ì´í„° í‰ê· í™” ì™„ë£Œ:', averagedDescriptor);
    setCapturedData(averagedDescriptor);
  };

  const handleSaveFaceData = () => {
    if (capturedData) {
      saveFaceDataToLocalStorage(capturedData);
      console.log('ğŸ’¾ ì‚¬ìš©ìì— ì˜í•´ ì–¼êµ´ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!');
    } else {
      console.log('âŒ ì €ì¥í•  ì–¼êµ´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  const drawDetailedFaceInfo = (
    ctx: CanvasRenderingContext2D,
    detections: faceapi.WithFaceLandmarks<{ detection: faceapi.FaceDetection }>
  ) => {
    const { detection, landmarks } = detections;
    const { x, y, width, height } = detection.box;

    ctx.strokeStyle = 'red';
    ctx.lineWidth = 3;
    ctx.strokeRect(x, y, width, height);

    ctx.fillStyle = 'red';
    ctx.font = '14px Arial';
    ctx.fillText(`X: ${Math.round(x)}, Y: ${Math.round(y)}`, x, y - 10);

    landmarks.positions.forEach((point, index) => {
      ctx.fillStyle = 'blue';
      ctx.beginPath();
      ctx.arc(point.x, point.y, 3, 0, Math.PI * 2);
      ctx.fill();
      ctx.fillText(`${index}`, point.x + 2, point.y - 2);
    });

    console.log('ğŸ“Œ ì–¼êµ´ ê°ì§€ ì¢Œí‘œ:', { x, y, width, height });
  };

  const stopCamera = () => {
    if (videoRef.current?.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream;
      stream.getTracks().forEach((track) => track.stop());
      videoRef.current.srcObject = null;
      console.log('ğŸ“´ ì›¹ìº  ì¢…ë£Œ');
    }
  };

  return (
    <div className="relative flex flex-col items-center">
      <video ref={videoRef} autoPlay muted className="border rounded w-80 h-60" />
      <canvas ref={canvasRef} className="absolute top-0 w-80 h-60" />
      <button onClick={handleFaceRegister} className="mt-2 p-2 bg-blue-500 text-white rounded">
        ì–¼êµ´ ê°ì§€ ì‹œì‘
      </button>
      <button onClick={handleSaveFaceData} className="mt-2 p-2 bg-green-500 text-white rounded">
        ì–¼êµ´ ë°ì´í„° ì €ì¥í•˜ê¸°
      </button>
    </div>
  );
}
